apiVersion: apps/v1
kind: Deployment
metadata:
  name: conbench-deployment
spec:
  selector:
    matchLabels:
      app: conbench
  replicas: 1
  strategy:
    rollingUpdate:
      maxSurge: 25%
      maxUnavailable: 25%
    type: RollingUpdate
  template:
    metadata:
      labels:
        app: conbench
    spec:
      containers:
      - name: conbench
        image: "<CONBENCH_CONTAINER_IMAGE_SPEC>"
        command: [
          "gunicorn",
          "-c", "conbench/gunicorn-conf.py",
          "-b", "0.0.0.0:5000",
          "-w", "5",
          "conbench:application",
          "--access-logfile=-",
          "--error-logfile=-"
          ]
        # for minikube local docker images
        # added via minikube image load <IMAGE_NAME>
        imagePullPolicy: Never
        #imagePullPolicy: "Always"
        ports:
          - name: gunicorn-port
            containerPort: 5000
        envFrom:
          - configMapRef:
              name: conbench-config
          - secretRef:
              name: conbench-secret
        resources:
          requests:
            # A request of zero CPU and memory effectively means "infinitely
            # small" for the scheduler deciding on which node to place the pod.
            # Use this technique to get things running on small GHA runners.
            memory: 0
            cpu: 0
        readinessProbe:
          failureThreshold: 1
          httpGet:
            path: /api/ping/
            port: 5000
            scheme: HTTP
          initialDelaySeconds: 60
          periodSeconds: 10
          successThreshold: 2
          timeoutSeconds: 20
      terminationGracePeriodSeconds: 60
---
apiVersion: monitoring.coreos.com/v1
# This is a CRD defined by the prometheus-operator/kube-prometheus project
kind: ServiceMonitor
metadata:
  name: conbench-service-monitor
spec:
  selector:
    matchLabels:
      app: conbench
  endpoints:
    # It's important that ServiceMonitor i) refers to a Service port  and ii)
    # refers to it via its name.
    - port: conbench-service-port
      path: /metrics
      scheme: http
      # This defines the time resolution.
      interval: 30s
---
apiVersion: v1
kind: Service
metadata:
  name: "conbench-service"
  labels:
    app: conbench
spec:
  ports:
  - name: conbench-service-port
    port: 80
    # The port number above: the port that will be exposed by this service.
    # `targetPort` is documented with "Number or name of the port to access on
    # the pods targeted by the service."
    targetPort: gunicorn-port
    protocol: TCP
  type: NodePort
  selector:
    app: "conbench"
---
# Create a bridge service of type ExternalName, pointing to a service in
# another k8s namespace via magic DNS name. This bridge service now is in the
# same namespace as the ingress rules defined further below (for an ingress
# rule to apply it must be set up in the same namespace as the service that it
# is referring to).
kind: Service
apiVersion: v1
metadata:
  name: grafana-bridge
spec:
  type: ExternalName
  externalName: grafana.monitoring.svc.cluster.local
---
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: ingress-conbenchservice
spec:
  rules:
  - host: conbench.local
    http:
      # A list of paths (for example, /testpath), each of which has an
      # associated backend defined with a service.name and a service.port.name
      # or service.port.number
      paths:
      - path: /
        pathType: Prefix
        backend:
          service:
            name: conbench-service
            port:
              number: 80
      - path: /grafana
        pathType: Prefix
        backend:
          service:
            name: grafana-bridge
            port:
              number: 3000
  ingressClassName: nginx
